\section{Application Context}

The app is to be developed to provide a proof-of-concept for the framework.
Basic tasks of the app include showing off the capabilities of the framework, proving the implementation, and as an example on how to utilize the framework.

The app will be developed for Android 4 and above, although the framework will be independent from any Android version.
The app will force landscape view as it offers the more natural layout for the layout of the app.
Apart from OpenCV for the framework, the app shall have no further dependencies on further 3rd party tools.
This should ensure a clean and fast code for the application.

The app should be capable of running smoothly on a Tegra 3 processor\footnote{See: \url{http://www.nvidia.com/object/tegra-3-processor.html}.}.
The development device is the Transformer Prime, a 10'' tablet from ASUS\footnote{See: \url{http://eee.asus.com/en/transformer-prime/features}.}.
This means that the app should run smoothly on a 1.6Ghz Quadcore ARM processor rendering to a 1280 by 800 pixel screen.

\section{System Tasks}

In this section, we will take a look at the various tasks the final app should be capable of doing.
Note that we differentiate between required tasks (meaning tasks that should reliably and completely work for the app to be considered done) and optional tasks (tasks that might be included, depending on time and scope of their implementation).

\subsection{Required Tasks}

\begin{tabulary}{\textwidth}{L || L}
View Camera & The user should, upon opening the app, be confronted with the view of the live camera feed. By default, if a marker is detected, a simple 3d coordinate marker is shown in place of an object. \\
\hline
Manage Model & Load, prepare, and remove a 3d model to be used within the app with a marker. Any model in a recognized format should be selectable as a file from a file browser. \\
\hline
Manage Markers & Allow for the management of multiple markers and their associations to the models. \\
\hline
Change Settings & Allows the user to modify the frames per second to render the output, how often to update the frame, and the visual quality of the video feed on which the marker detection is run. Should enable the app to be adapted to run on a wide variety of devices.\\
\hline
Toggle Debugging Information & If desirable, the user can toggle a debugging view to be rendered on top of the feed. This should offer detailed information on the shown view, marker detection, and any other factors. \\
\hline
Screenshot & As Android does not offer a screenshot tool by default, an option to capture the feed shall be provided. \\
\end{tabulary}

\subsection{Optional Tasks}

This section represents tasks that could be added but might not be.
Any feature that does not make the final app is to be taken as a suggestion for possible future expansion.

\begin{tabulary}{\textwidth}{L || L}
Marker Definition & If possible, the user can load any recognized picture to be used as a marker beyond the default one. Certain properties will most likely be required of the picture however. \\
\hline
Modify Model & This task shall allow the user to change basic properties such as rotation and scale of a loaded object. Further options might be toggling the rendering of a wireframe or textures. Future work might even include shader control or blending options for transparency or blur.\\
\hline
Multiple Tracker Support & Enable the app to track multiple markers at once and render their objects simultaneously.\\
\hline
Primitive Objects & Allow basic text or pictures to be used directly as an object without having to build them manually in a 3d modeling program. This feature would enable fast prototyping for text- and picture-based AR.\\
\hline
Camera Chooser & For devices that have multiple cameras, allow the user to choose which one to use as source for the live view and the rendering.\\
\end{tabulary}

\section{Dialog Structure}

\begin{figure}
	\centering
	\includegraphics[width=10cm]{img/dialogs.eps}
	\caption[App Dialog Structure.]{Overview of the dialog structure of the app. Except where otherwise noted, all actions from one dialog to another are a simple touch.}
	\label{fig:dialog_structure}
\end{figure}

Figure \ref{fig:dialog_structure} shows a graph of the usage flow in the app graphical user interface.
Note that apart from the layout change from just the main screen to the screen with the menu displayed at the right border, all sub-menus are displayed in-place to the original menu.
This allows the main purpose of the app, namely the rendering of AR, to always be in the focus of the user.
This enables rapid and direct feedback to any changes the user does within the menus.

\section{Mockups}

\begin{figure}
	\centering
	\includegraphics[width=12cm]{img/main_nomenu.png}
	\caption[Start Screen Mockup.]{Mockup of how the start screen of the final app might look. Note the menu partially hidden to the right, the rendered axes, and the green status light signifying that the marker is being read with a high confidence.}
	\label{fig:main_nomenu}
\end{figure}

Upon starting the app on a capable device, the app presents itself as shown in Figure \ref{fig:main_nomenu}.
This is effectively the start screen from where all the interaction takes place.

The green light in the top left shows that the app is detecting the marker with a high confidence, meaning that there are no large uncertainties.
If the marker is too warped or partially covered, the light switches to red.
If the app can still detect the marker but is having difficulties, the light switches to orange.
This mechanism is meant to offer fast and accurate feedback to the detection capability.
Another method of direct feedback is the already displayed axis-object.
This is meant to offer fast feedback to the orientation and scaling of the coordinate space to the user before a custom object is displayed.
The visibility of the axis-object can be toggled in the settings.

The menu on the right can be swiped in to be fully displayed.
The four main points are <Paired Elements>, <Markers>, <Settings>, and <Record>.

\begin{figure}[H]
	\centering
	\minipage{0.49\textwidth}
		\centering
		\includegraphics[width=0.5\linewidth]{img/menu_paired.png}
		\caption[Paired Element Menu Mockup.]{Mockup of the <Paired Elements> part of the main menu. From here, the user can select to work on an existing pair or add a new one.}
		\label{fig:menu_paired}
	\endminipage\hfill
	\minipage{0.49\textwidth}
		\centering
		\includegraphics[width=0.5\linewidth]{img/menu_paired_add.png}
		\caption[Paired Element Pair Add Menu Mockup.]{Mockup of the menu to add a new pair to use. Here the initial marker and object can be chosen, along with any exposed options before creating the pairing for active use.}
		\label{fig:menu_paired_add}
	\endminipage\hfill
	\minipage{0.9\textwidth}
		\centering
		\includegraphics[width=0.25\linewidth]{img/menu_paired_pair.png}
		\caption[Paired Element Pair Menu Mockup.]{Mockup of the menu for modifying existing pairs, including removing them. Note the switch to use a pair and the preview of the marker and object with the ability to change both.}
		\label{fig:menu_paired_pair}
	\endminipage\hfill
\end{figure}

Figure \ref{fig:menu_paired} shows the <Paired Elements> menu, which lists the current paired marker-object pairs that the app can detect.
From here, the user can modify existing pairs by touching them, which opens a new menu shown in Figure \ref{fig:menu_paired_pair} in place with options pertaining to that pair, including its removal.
Adding new pairs is done via the <Add> button at the top, displaying the menu as in Figure \ref{fig:menu_paired_add} to select the marker and object to pair.

\begin{figure}[H]
	\centering
	\minipage{0.49\textwidth}
		\centering
		\includegraphics[width=0.5\linewidth]{img/menu_marker.png}
		\caption[Marker Element Menu Mockup.]{Mockup of the <Marker> sub-menu of the main menu. From here, modifying and adding new markers is provided.}
		\label{fig:menu_marker}
	\endminipage\hfill
	\minipage{0.49\textwidth}
		\centering
		\includegraphics[width=0.5\linewidth]{img/menu_marker_add.png}
		\caption[Marker Add Menu Mockup.]{Mockup for adding a new marker by choosing a suitable image file to use.}
		\label{fig:menu_marker_add}
	\endminipage\hfill
	\minipage{0.9\textwidth}
		\centering
		\includegraphics[width=0.25\linewidth]{img/menu_marker_modify.png}
		\caption[Modify Marker Menu Mockup.]{Modifying existing markers is done in this mockup. This includes the option to delete a marker.}
		\label{fig:menu_marker_modify}
	\endminipage\hfill
\end{figure}

<Markers>, as seen in Figure \ref{fig:menu_marker}, lists the available markers and provides options for organizing them.
Again, touching a marker opens an in-place menu with options, as in Figure \ref{fig:menu_marker_modify}.
Adding new markers via Figure \ref{fig:menu_marker_add}, either by loading a picture, using a default, or taking a picture from the camera, can be done via the <Add> button.

\begin{figure}[H]
	\centering
	\includegraphics[width=4cm]{img/menu_settings.png}
	\caption[Settings Menu Mockup.]{This mockups depicts the <Settings> menu. From here, the user should be allowed to change a few general settings of the app and to read the <About> page.}
	\label{fig:menu_settings}
\end{figure}

The <Settings> menu seen in Figure \ref{fig:menu_settings} is just that.
Here, the user can change app-specific settings such as video resolution, directories, debugging information, and more.

\begin{figure}[H]
	\centering
	\includegraphics[width=4cm]{img/menu_record.png}
	\caption[Record Menu Mockup.]{This mockup shows the panel for the <Record> menu, from which a screenshot or a short video clip can be taken of the output of the app.}
	\label{fig:menu_record}
\end{figure}

<Record> allows the user to record the current rendering, either as a picture or possibly as a video.
The options beneath this item are for controlling those features.
