This section provides a commentary of the implementation work of the framework.
We will also take a closer look at the performance of the finished framework and where improvements can be made in the future.
To allow our work to be put into perspective, we will also compare the framework with the Aruco framework.

\section{Implementation}
\label{implementation}

\subsection{Encountered Difficulties}

% Sparse help
The first major difficulty we encountered upon beginning the implementation was the user generated documentation of the Java OpenCV for Android framework in the form of questions and answers or tutorials.
The probable cause for this is most likely due to the fact that OpenCV was originally written for desktop applications using C++.
That means that there are two major differences between the more widely used and documented version of the framework compared to the version used for this project.
The first is that one of the goals of our work was to write a Java framework, thus encouraging that we use the Java wrapper for OpenCV – thus making the majority of C++ resources moot and hard to use.
The second difference is due to the fact that our framework's platform was to be Android, for which a few small differences existed compared to the normal use of OpenCV – such as the use of OpenCV via the elegant solution of a separate application, the OpenCV manager.
These two differences seem to have been sufficient in decreasing the usage of the Java port of OpenCV enough that documentation and accessible tutorials and examples proved to be far in between.
This forced development to rely all too often on examples written for other platforms and programming languages.
Luckily however the framework syntax is consistent, although the used data types are not always transferable.
Thus such translation work was possible if difficult.

% Lacking documentation
But not only unofficial documentation is lacking: official documentation in the form of documentation for the application programming interface and official tutorials are, for all intents, almost non existent at the time of this paper.
Comparably to the lacking user generated documentation, this can be mitigated by using material intended for C++.
C++ documentation is also all there is for the Javadoc used within the IDE.
It is not easy working in Java with C++ code as Javadoc, with further text mostly not relevant to the problems encountered when coding with it.

% Problems with stupid mat
While we're on the topic of the C++ base of OpenCV, allow us to criticize the single most frustrating aspect of using OpenCV: the matrix object data type, short mat.
Mats are used within OpenCV as a one-size-fits-all solution for any data ranging from vector points that represent polygons to multi-channel images in various more or less used formats.
While it was still easy to recognize the RGBA format\footnote{RGBA stands for, respectively: red, green, blue, alpha. This depicts the order and type of channels for an image.} that the framework receives the camera image in, using the correct conversions and the correct mat subtypes in the principle work thread within Imagine proved to be very frustrating.
First we encountered difficulties with the conversion of different image formats to other formats, an operation that costs a good bit of processing power and time.
Thankfully, we were able to work around any conversions by parallel usage of multiple mats whose results are used on one another to retain a higher overall speed.
Then another difficulty emerged while using the OpenCV function to calculate polygons for detected contours within an image.
The method for these polygons returns these in a special mat subtype that is specialized for floating point numbers.
However, the methods we then required to work with these polygons required the polygons in a normal mat, thus forcing us to convert from one type of mat to another.
Again this problem could largely be mitigated by converting as little as possible, although the base conversion proved to be one of the smaller problems in the grand scope of speed within the Imagine worker threads.
Furthermore, there exist no methods for determining the type and allocation of channels within a mat.
While not being able to check for these properties forced a clean usage of the data class within Imagine and thus probably increased speed somewhat, such methods are crucial for learning the correct usage of mat and certainty of stored data type.
Writing and reading data with mats is also something that requires faith, as no checks for sanity can be performed on the data.
For example, the method for reading a single coordinate returns a double array – always, even when using the mat for binary images (in which case a boolean would suffice), luminance images (possibly a short data type), or as an integer matrix (integers).
The returned value then has to be cast to the (hopefully) correct data type – and if we made a mistake somewhere along the line and the mat doesn't contain the data we expect it to contain, we have little in the way of catching that mistake.
We therefore kindly suggest that OpenCV for Android make use of the Java generics mechanism, as we believe that would start to simplify the confusion surrounding mats.

% Problems debugging
A further difficulty proved to be the debugging of errors while programming the worker threads within Imagine.
This came from the fact that OpenCV runs in C++ even on Android and tracing errors to their source thus proved difficult.
Often only careful consideration of error messages and stack traces in the depths of the Android log allowed any progress to be made in tracing a bug, although mostly trial and error proved to be the primary method of correcting these errors.
Problems debugging errors were also due to the paradigm differences in error handling between how Java in general does it (using so-called exceptions) and C++ does it (using integers as error codes).
OpenCV for Android does not cast the numeric error codes into equivalent Java exceptions, instead leaving them as-is.
Furthermore, the numerical error codes proved to be very generic in their implications.
An example of this can be found with the error code we mostly fought with, which was 215.
That numerical error can (and does!) mean anything from incorrect mat sizes to incorrect number of channels.
A quick search also showed that that very same code is also used to signal unimplemented methods within OpenCV itself.

% Paradigm problems
While on the topic of paradigm differences: another difficulty we encountered with OpenCV for Android was the difference in coding styles.
With this we mean for example that the result of a method was not returned, but instead written into an object passed on to the method\footnote{This stems from the way C++ usually does error handling by returning numerical error codes. The result is written into a referenced data class, freeing the return call for passing back numerically coded error or success messages.}.
Due to the existence of exceptions, this is usually done differently when using Java.
While generally more of a nuisance than a source of error, it would be helpful if the wrapper took care of the paradigm shift between Java and the C++ interface, thus freeing developers from having to work with two paradigms in parallel.

% General
Generally speaking, OpenCV for Android proved usable for this work, but with some difficulty, as can be seen by the lengthy dissection here.
OpenGL ES proved to relatively trivial to use, notably because of the wealthy online resources in the form of extensive documentation and multiple tutorials.
The only bigger difficulties encountered while working with OpenGL ES were using multidimensional math for the matrix operations and how to get the renderer to render to a transparent layer.

\subsection{Performance}
\label{performance}

Here, we will take a brief look at the general performance of the Imagine framework.
All numbers that will be given are approximations only, as we did not statistically analyze them.
For a more in depth look of Imagine's performance, further work can be done as necessary.

To give the following numbers a frame of reference, here some numbers concerning the general speed of the Android platform, and the OpenGL ES and OpenCV utilization on it.

OpenCV captures the preview frame of the camera from Android for the base frame from which all processing originates.
This means that the speed at which it does this is the first important reference for all further values.
The speed of this operation proves to be the first limiting factor: due to how Android camera capture works, the preview only offers 15 frames per second.
This has some strong implications for the Imagine framework: however much the work done can be optimized, it will never be capable of running faster than that.
As humans only begin to see a smooth video upwards of approximately 20 frames per second – for perfectly smooth video however at least 60 frames per second – this places Imagine already outside the range of smooth output.

Android itself renders the interface at 60 frames per second\footnote{As of Android 4.1.}.
OpenGL ES also easily achieves 60 frames per second, although it is to note that the graphic pipeline has the advantage of serious hardware acceleration.
Of course the speed at which OpenGL ES will render a scene for the Imagine framework is highly dependent on the complexity of the models, although that should not be a limiting factor for some time yet.

The comparison of these two limiting factors shows that Imagine is mainly performance dependent on the OpenCV for Android framework.
Newer versions of it should theoretically be able to increase the speed up to the framerate of the camera preview.
To achieve even higher speeds, the speed at which Android fetches the camera preview must be increased, which could happen with newer devices and or newer version of Android.
All of these possible speed increases however lie outside of the influence of the Imagine framework.

For the speed of the Imagine framework, a general understanding of the algorithm that detects markers is required – as can be found in section \ref{detection_workflow}.
Imagine idles at seven frames per second, meaning that this is the best case performance under ideal circumstances with no markers present.
When markers are present and detected, performance takes a hard dip.
Six markers can be detected at a bit above two frames per second.
This effect only increases with more active markers within the camera view.

TODO: CONTINUE with step by step numbers in ms.

----------------------- TODO: Framework and app -----------------------

Compared to the feature detection approach, this algorithm can easily manage up to four frames per second.
However, while four is better than two frame per second, it is still somewhat too slow for easy use.
Therefor, we suggested and implemented multitasking to process multiple frames in parallel.
This allows the framework to run with around seven frame per second for one marker.

This low increase may have a few reasons, of which the most likely is probably that OpenCV is currently not multi-
threading capable.
As it does improve performance, we decided to keep it.

\section{Features and Capabilities}

TODO: Place screenshots of debugging views and finished output here.
Also mention helpers here?

\section{Comparison to similar Apps}

TODO: Compare with aruco.
